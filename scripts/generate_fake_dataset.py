from datetime import datetime
import json
from pathlib import Path

from loguru import logger
import numpy as np
import pandas as pd
import typer


DATETIME_FORMAT = "%Y-%m-%dT%H:%M:%S"
REPO_ROOT = Path(__file__).parents[1]

app = typer.Typer(add_completion=False)


def create_fake_features(
    column_values: dict,
    n: int,
    start_time: datetime,
    end_time: datetime,
    output_path: Path,
    rng: np.random.RandomState,
):
    df = pd.DataFrame(
        {column: rng.choice(column_values[column], size=n) for column in column_values}
    )
    df["timestamp"] = pd.date_range(start_time, end_time, periods=len(df))
    output_path.parent.mkdir(exist_ok=True, parents=True)
    df.to_csv(output_path, index=False, date_format=DATETIME_FORMAT)


@app.command()
def main(
    fake_feature_params_path: Path = typer.Argument(
        REPO_ROOT / "scripts" / "fake_feature_params.json",
        help="Path to a JSON file with fake data parameters.",
    ),
    submission_format_path: Path = typer.Argument(
        REPO_ROOT / "scripts" / "fake_submission_format.csv.bz2",
        help="Path to a sample submission format.",
    ),
    output_directory: Path = typer.Option(
        REPO_ROOT / "runtime" / "data",
        help="Directory where the development dataset will be saved.",
    ),
    seed: int = 10,
):
    """Generates a small, not very realistic data that nonetheless can stand in as the features and
    submission format for testing out the code execution submission.

    Reads fake data parameters where each feature CSV is described by the column names and 10 sample
    values for each column. 100 rows are simulated by sampling (with replacement) from those sample
    values. The start time for the fake data is the first time in the submission format, and the end
    time is the last time in the submission format. The labels are generated by randomly selecting
    one configuration per airport to be active the entire time.
    """
    logger.info("Generating fake data to {}", output_directory)
    submission_format = pd.read_csv(submission_format_path, parse_dates=["timestamp"])
    start_time = submission_format.iloc[0].timestamp
    end_time = submission_format.iloc[-1].timestamp

    logger.debug("Simulating features from {} to {}.", start_time, end_time)

    with Path(fake_feature_params_path).open("r") as fp:
        fakes = json.load(fp)

    rng = np.random.RandomState(seed=seed)
    for fake in fakes:
        create_fake_features(
            fake["values"],
            n=100,
            start_time=start_time,
            end_time=end_time,
            output_path=output_directory / fake["relative_path"],
            rng=rng,
        )

    logger.debug(
        "Saving submission format with {:,} rows x {} columns.",
        len(submission_format),
        len(submission_format.columns),
    )
    submission_format.to_csv(
        output_directory / "submission_format.csv",
        date_format=DATETIME_FORMAT,
        index=False,
    )

    labels = submission_format.copy().assign(active=0)
    active_configs = (
        submission_format.groupby("airport")
        .config.sample(1, random_state=rng)
        .sort_values()
    )
    logger.debug(
        "Assigning the following active configurations {}.",
        ", ".join(active_configs.values),
    )
    labels.active.where(
        ~labels.config.isin(active_configs.values), other=1, inplace=True
    )
    assert (
        labels.groupby(["airport", "timestamp", "lookahead"]).active.sum() == 1
    ).all(), (
        "More than one active configuration present for an airport/timestamp/lookahead."
    )

    logger.debug(
        "Saving fake labels {:,} rows x {} columns.",
        len(labels),
        len(labels.columns),
    )
    labels.to_csv(
        output_directory / "test_labels.csv",
        date_format=DATETIME_FORMAT,
        index=False,
    )


if __name__ == "__main__":
    app()
